---
description: 'R2D2: Repeatable and Reliable Detector and Descriptor'
---

# \[NIPS 2019] R2D2

{% embed url="http://arxiv.org/abs/1906.06195" %}

{% embed url="https://github.com/naver/r2d2" %}

### Abstract

作者在这篇工作中，提出一个观点：

> In this work, we argue that salient regions are not necessarily discriminative, and therefore can harm the performance of the description. Furthermore, we claim that descriptors should be learned only in regions for which matching can be performed with high confidence.

简单来说，就是之前的训练detector的方法，都是更关注检测出的特征是否repeative，这样的特征可能不够discriminative，比如重复性的纹理。所以作者认为，这样的训练方法有弊端。并且由于提取的salient region不够discriminative，所以descriptor的训练也不够完善。所以这篇工作中，作者要提取sparse，repeative and disciminative特征，依旧使用detect-and-descibe的提取方法。

### Introduction

![](<../../.gitbook/assets/image (366).png>)

作者先更详细直观地阐述了一下motivation，就像上面这两幅示例图。第一幅图中，对于detector来说，只有黑三角形附近的区域是有利于提取keypoint的，但是所有包含该三角形的patch都可以提取同等可靠的descriptor，所以匹配的时候会有误差。第二幅图中，对于detector，所有棋盘网格的角点都可以提取出同等可靠的keypoint，但是它们都不利于提取descriptor，因为完全重复，匹配的时候会出现混淆。 所以，在这篇论文，作者认为detection和description是不可分割的，要一起训练（其实就是detect-and-descibe），并且提取的特征不仅要repeatable还需要reliable for matching（感觉就是discrimative）。所以R2D2会分别根据basenet输出的feature map分别得到repeatability confidence map和reliability confidence map，然后综合两张map提取特征。

### Methods

![](<../../.gitbook/assets/image (163).png>)

R2D2采用全卷积网络结构，输入H x W大小的图像，输出三部分：第一部分D x H x W feature map X，视作H x W个D维局部特征，每个像素对应一个局部特征；第二部分是一个H x W heatmap S，每个位置上的值代表该点特征的sparse和repeatable，值在\[0,1]之间，为了获得稀疏的特征，只提取S中局部最大值作为特征；第三部分是H x W heatmap R，对应特征的reliability或者说disciminativeness. 网络的backbone选用L2-net（不降低分辨率），但是将最后一个8x8的卷积换做3个2x2卷积，来减少参数。D=128。为了获得S和R，在backbone后接了两个1x1卷积+softmax。

### Loss

#### repeatability

首先训练特征的repeatability，作者认为

> In fact, using supervision essentially boils down in this case to copying an existing detector rather than discovering better and easier keypoints.

就是用监督学习的训练方法，只是在学习那些现成的detector的检测策略（这个意义上讲，superpoint其实也是这样的，只不过通过homographic adaptation进行了一个data augmentation，去提升性能）。所以作者希望直接训练S，让其跟随图像变换而一起变换。&#x20;

假设图1，图2，当图像是真实图像时，用optical flow或stereo matching的方法去获得两幅图像中像素级的对应关系U，当图像是虚拟的仿真图像时，那么U可以直接获得了。分别获得两幅图像的S和S'，利用U将S'对应到$${S'}_{U}$$。如果S是covariant to transformations，那么S和$${S'}_{U}$$应该是一致的。&#x20;

所以，可以直接对S和$${S'}_{U}$$求取cosine相似度，相似度越大，说明S的表现越好，但是warp后可能会出现occlusions、warp artifacts or border effects，所以作者用了一个局部的cosine相似度，求取多个patch的cosine相似度： &#x20;

![](<../../.gitbook/assets/image (200).png>)

$$L_{cosine}$$只能保证S和$${S'}_{U}$$相似，但是容易导致S和$${S'}_{U}$$变成常值。由于最后使用S是要挑选local maxima，所以还需要让S的局部峰值变大：&#x20;

![](<../../.gitbook/assets/image (341).png>)

最后，训练repeatability的loss就是以上两部分的加权：&#x20;

![](<../../.gitbook/assets/image (1043).png>)

#### Reliability, i.e., Discriminativeness

这部分是为了得到一个可以度量discriminative的score map，让具有discriminative descriptor的区域具有较大的可信度。&#x20;

使用Average Precision Loss进行训练descriptor，就是给一对ground-truth batch，计算batch1中每个descriptor与batch2中每个des之间的距离，然后计算batch中每个query的AP loss，用下面公式进行训练：&#x20;

![](<../../.gitbook/assets/image (892).png>)

这篇论文中也用到了AP loss，区别在于原本AP loss使用标准的keypoint detector去提取ground-truth batch，而在这里根据前文可以知道，提供了U，所以直接用U就可以获得ground-truth batch了。

&#x20;在这一部分，作者还提出，想要提取利于匹配的特征，不光要考虑图像纹理的丰富度，还要考虑其是否discriminative。所以作者用R去筛选discriminative region中的特征，只有这部分特征会对网络训练产生影响。&#x20;

![](<../../.gitbook/assets/image (678).png>)

使用这种loss，为了使loss减小，当AP(i,j)小于k时，即该点descriptor不够discriminative，那么Rij应当为0,；当该点descriptor足够discriminative时，$$R_{ij}$$应当为1。在实验中，作者发现k=0.5可以达到比较好的效果。

### Test

在测试时，也采用了图像金字塔去获取更丰富的特征，从原分辨率开始，逐渐下采样，直到图像小于128px。每次从图像中利用S的局部最大值提取特征，保存相应位置的描述子。最后从所有保存的特征中，根据SR挑选top-K特征。

### Training

R2D2需要获得图像间的ground-truth correspondence。所以作者提出两种方法，一种就是常规的图2是由图1经过一种确定的transformation变换而来的；另一种，是来自图像序列或无序图像中的一对图像。第二种方法区别于之前用SfM验证获得dense correspondence的方法，这种方法输入一对图像和一些稀疏的SfM验证过的点，用光流工具来获得correspondence。第一步，作者先用sfm生成图像的3D点与6DoF位姿（sparse），对于视觉有足够重叠的图像，用sfm提供的2D correspondence计算F matrix（作者发现这比直接用图像位姿去算要更可靠），然后用EpicFlow获得高质量的dense correspondence。作者在DeepMatching（EpicFLow的第一步，可以获得semi-dense correspondence）中加入epipolar constraint来增强方法。此外，作者还预测了光流可信度的mask。对于DeepMatching的输出，作者计算了一个connected consistent neighbors的图，只保留属于较大（至少有50个matches）connected component的matches，然后用一个thresholded kernel density estimator在验证后的matches中估计一个mask，作为optical flow可信度的度量。

### Data

Oxford，Paris，Aachen Day-Night.&#x20;

在训练时，在裁剪到192x192大小的第一张图像（query）中，在8x8像素大小的网格上对像素进行采样。第二张图像中，考虑query对应的像素，以及在以8像素为步长的规则网格上采样得到的像素。作者将光流对应位置4像素以内的像素定义为positives，将该位置8像素以外的像素作为negatives。

### Results

![](<../../.gitbook/assets/image (498).png>)

![](<../../.gitbook/assets/image (357).png>)

![](<../../.gitbook/assets/image (177).png>)

这张图很直观的表现出r2d2的优点，对于repeatability来说（第2行图），天空是可重复性很高的，但是对于特征来说，由于天空有大量重复纹理或无纹理，所以不利于区分，所以其上的特征reliability很低，r2d2综合考虑了这两点，所以提取的特征比较好。&#x20;

![](<../../.gitbook/assets/image (358).png>)

由于R2D2是在NxN的滑窗上检测local maxima作为关键点，所以N的值会影响特征。&#x20;

![](<../../.gitbook/assets/image (1077).png>)

消融实验，说明两个特性显性的去训练是有意义的。

![](../../.gitbook/assets/r2d2\_2.png)

![](<../../.gitbook/assets/image (1013).png>)

在HPatches上的效果。&#x20;

![](<../../.gitbook/assets/image (562).png>)

在Aachen day-night上的效果。
