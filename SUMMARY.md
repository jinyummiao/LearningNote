# Table of contents

* [About me](README.md)

## TOOLS

* [学术表达](tools/xue-shu-biao-da/README.md)
  * [表述](tools/xue-shu-biao-da/biao-shu.md)
  * [专用名词及缩写](tools/xue-shu-biao-da/zhuan-yong-ming-ci-ji-suo-xie.md)
* [Linux常用指令](tools/linux-chang-yong-zhi-ling.md)
* [Git常用指令](tools/git-chang-yong-zhi-ling.md)
* [Docker常用指令](tools/docker-chang-yong-zhi-ling.md)

## Features

* [hand-crafted features](features/hand-crafted-features/README.md)
  * [\[ACC 1998\] Harris角点](features/hand-crafted-features/acc-1998-harris-jiao-dian.md)
  * [\[IJCV 2004\] SIFT特征](features/hand-crafted-features/ijcv-2004-sift-te-zheng.md)
  * [\[CVIU 2008\] SURF特征](features/hand-crafted-features/cviu-2008-surf-te-zheng.md)
  * [\[ICCV 2011\] ORB特征](features/hand-crafted-features/iccv-2011-orb-te-zheng.md)
* [deep local features](features/deep-local-features/README.md)
  * [\[arxiv 2017\] MagicPoint](features/deep-local-features/arxiv-2017-magicpoint.md)
  * [\[CVPRW 2018\] SuperPoint](features/deep-local-features/cvprw-2018-superpoint.md)
  * [\[CVPR 2019\] D2-Net](features/deep-local-features/cvpr-2019-d2-net.md)
  * [\[NIPS 2019\] R2D2](features/deep-local-features/nips-2019-r2d2.md)
  * [\[arxiv 2020\] SEKD](features/deep-local-features/arxiv-2020-sekd.md)
  * [\[CVPR 2020\] ASLFeat](features/deep-local-features/cvpr-2020-aslfeat.md)
  * [\[ICCV 2021\] MDA](features/deep-local-features/iccv-2021-mda.md)
  * [\[NIPS 2020\] DISK](features/deep-local-features/nips-2020-disk.md)
  * [\[ECCV 2020\] DELG](features/deep-local-features/eccv-2020-delg.md)
* [patch descriptor](features/patch-descriptor/README.md)
  * [\[CVPR 2021\] L2-Net](features/patch-descriptor/cvpr-2021-l2-net.md)
  * [\[CVPR 2018\] DOAP](features/patch-descriptor/cvpr-2018-doap.md)
* [deep global features](features/deep-global-features/README.md)
  * [\[CVPR 2016\] NetVLAD](features/deep-global-features/cvpr-2016-netvlad.md)
  * [\[CVPR 2021\]Patch-NetVLAD](features/deep-global-features/cvpr-2021-patch-netvlad.md)
  * [\[RSS 2018\] CALC](features/deep-global-features/rss-2018-calc.md)
  * [\[IROS 2019\] CALC2.0](features/deep-global-features/iros-2019-calc2.0.md)
  * [\[ICMR 2020\] MSCFP](features/deep-global-features/icmr-2020-mscfp.md)
  * [\[RAL 2020\] CoHOG](features/deep-global-features/ral-2020-cohog.md)
  * [\[TIP 2019\] REMAP](features/deep-global-features/tip-2019-remap.md)
* [feature matcher](features/feature-matcher/README.md)
  * [\[CVPR 2020\] SuperGlue](features/feature-matcher/cvpr-2020-superglue.md)
  * [\[CVPR 2021\] LoFTR](features/feature-matcher/cvpr-2021-loftr.md)
  * [\[ECCV 2020\] AdaLAM](features/feature-matcher/eccv-2020-adalam.md)
  * [\[CVPR 2021\] Patch2Pix](features/feature-matcher/cvpr-2021-patch2pix.md)

## 3D Vision

* [learning note](3d-vision/learning-note/README.md)
  * [Camera model](3d-vision/learning-note/camera-model.md)
* [calibration](3d-vision/calibration/README.md)
  * [\[CVPR 2021\] DeepI2P](3d-vision/calibration/cvpr-2021-deepi2p.md)
  * [\[RAL 2022\] EFGHNet](3d-vision/calibration/ral-2022-efghnet.md)
  * [OpenCalib](3d-vision/calibration/opencalib.md)
* [deep VO/SLAM](3d-vision/deep-vo-slam/README.md)
  * [\[NIPS 2021\] DROID-SLAM](3d-vision/deep-vo-slam/nips-2021-droid-slam.md)
  * [\[ICCV 2021\] iMAP](3d-vision/deep-vo-slam/iccv-2021-imap.md)
  * [\[3DV\] 8-Point ViT](3d-vision/deep-vo-slam/3dv-8-point-vit.md)
  * [\[arxiv 2022\] AutoMerge](3d-vision/deep-vo-slam/arxiv-2022-automerge.md)
* [traditional VO/SLAM](3d-vision/traditional-vo-slam/README.md)
  * [\[IROS 2021\] RP-VIO](3d-vision/traditional-vo-slam/iros-2021-rp-vio.md)
  * [\[TRO 2021\] ORB-SLAM3](3d-vision/traditional-vo-slam/tro-2021-orb-slam3.md)
  * [\[TPAMI 2018\] DSO](3d-vision/traditional-vo-slam/tpami-2018-dso.md)
* [NeRF](3d-vision/nerf/README.md)
  * [\[ICCV 2021\] iMAP](3d-vision/nerf/iccv-2021-imap.md)
  * [\[ECCV 2020\] NeRF](3d-vision/nerf/eccv-2020-nerf.md)
  * [\[CVPR 2022\] Mega-NeRF](3d-vision/nerf/cvpr-2022-mega-nerf.md)
* [BEV](3d-vision/bev/README.md)
  * [\[CVPRW 2021\] HDMapNet](3d-vision/bev/cvprw-2021-hdmapnet.md)
  * [\[ECCV 2020\] LSS](3d-vision/bev/eccv-2020-lss.md)
  * [\[arxiv 2022\] VectorMapNet](3d-vision/bev/arxiv-2022-vectormapnet.md)
  * [\[arxiv 2022\] MapTR](3d-vision/bev/arxiv-2022-maptr.md)
* [Localization](3d-vision/localization/README.md)
  * [survey and analysis](3d-vision/localization/survey-and-analysis/README.md)
    * [\[ICCV 2021\] pGT in VisLoc](3d-vision/localization/survey-and-analysis/iccv-2021-pgt-in-visloc.md)
    * [\[3DV 2020\] IR in VisLoc](3d-vision/localization/survey-and-analysis/3dv-2020-ir-in-visloc.md)
    * [\[Sensors 2022\] Localization in highway scenarios](3d-vision/localization/survey-and-analysis/sensors-2022-localization-in-highway-scenarios.md)
    * [\[arxiv 2022\] Localization using LiDARs and Cameras](3d-vision/localization/survey-and-analysis/arxiv-2022-localization-using-lidars-and-cameras.md)
    * [\[JIoT 2018\] SOTA Localization Techniques](3d-vision/localization/survey-and-analysis/jiot-2018-sota-localization-techniques.md)
    * [\[IV 2020\] LiDAR Localization](3d-vision/localization/survey-and-analysis/iv-2020-lidar-localization.md)
  * [pose regression](3d-vision/localization/pose-regression/README.md)
    * [\[ICCV 2015\] PoseNet](3d-vision/localization/pose-regression/iccv-2015-posenet.md)
    * [\[ICCVW 2017\] HourglassNet](3d-vision/localization/pose-regression/iccvw-2017-hourglassnet.md)
    * [\[CVPR 2017\] PoseNet2](3d-vision/localization/pose-regression/cvpr-2017-posenet2.md)
    * [\[AAAI 2020\] AtLoc](3d-vision/localization/pose-regression/aaai-2020-atloc.md)
    * [\[ICCV 2019\] Local Supports Global](3d-vision/localization/pose-regression/iccv-2019-local-supports-global.md)
    * [\[ICCV 2021 \]Multi-scene Transformer](3d-vision/localization/pose-regression/iccv-2021-multi-scene-transformer.md)
    * [\[CVPRW 2020\] MultiScene PoseNet](3d-vision/localization/pose-regression/cvprw-2020-multiscene-posenet.md)
    * [\[CVPR 2018\] MapNet](3d-vision/localization/pose-regression/cvpr-2018-mapnet.md)
    * [\[arxiv 2021\] auxiliary colorization](3d-vision/localization/pose-regression/arxiv-2021-auxiliary-colorization.md)
    * [\[ICCVW 2019\] How to improve](3d-vision/localization/pose-regression/iccvw-2019-how-to-improve.md)
    * [\[BMVC 2018\] Anchor points](3d-vision/localization/pose-regression/bmvc-2018-anchor-points.md)
    * [\[ICRA 2016\] Bayesian PoseNet](3d-vision/localization/pose-regression/icra-2016-bayesian-posenet.md)
    * [\[RAL 2020\] GN-Net](3d-vision/localization/pose-regression/ral-2020-gn-net.md)
    * [\[IROS 2020\] deepFEPE](3d-vision/localization/pose-regression/iros-2020-deepfepe.md)
    * [\[arxiv 2021\] E2E RPE](3d-vision/localization/pose-regression/arxiv-2021-e2e-rpe.md)
    * [\[ECCV 2018\] DeepF](3d-vision/localization/pose-regression/eccv-2018-deepf.md)
    * [\[3DV\] Direct PoseNet](3d-vision/localization/pose-regression/3dv-direct-posenet.md)
  * [place recognition](3d-vision/localization/place-recognition/README.md)
    * [\[IROS 2009\] Online Visual Vocabulary](3d-vision/localization/place-recognition/iros-2009-online-visual-vocabulary.md)
    * [\[TRO 2012\] Online Visual Vocabulary](3d-vision/localization/place-recognition/tro-2012-online-visual-vocabulary.md)
    * [\[TRO 2012\] DBoW](3d-vision/localization/place-recognition/tro-2012-dbow.md)
    * [\[IROS 2014\] ABLE](3d-vision/localization/place-recognition/iros-2014-able.md)
    * [\[ICRA 2015\] IBuILD](3d-vision/localization/place-recognition/icra-2015-ibuild.md)
    * [\[CVPR 2016\] NetVLAD](3d-vision/localization/place-recognition/cvpr-2016-netvlad.md)
    * [\[IROS 2016\] Encoding Image Sequences](3d-vision/localization/place-recognition/iros-2016-encoding-image-sequences.md)
    * [\[IROS 2017\] Semantic SeqSLAM](3d-vision/localization/place-recognition/iros-2017-semantic-seqslam.md)
    * [\[RSS 2018\] CALC](3d-vision/localization/place-recognition/rss-2018-calc.md)
    * [\[RAL 2018\] iBoW-LCD](3d-vision/localization/place-recognition/ral-2018-ibow-lcd.md)
    * [\[RSS 2018\] LoST](3d-vision/localization/place-recognition/rss-2018-lost.md)
    * [\[ICRA 2018\] Don't look back](3d-vision/localization/place-recognition/icra-2018-dont-look-back.md)
    * [\[ICRA 2018\] VWs to Places](3d-vision/localization/place-recognition/icra-2018-vws-to-places.md)
    * [\[RAL 2019\] BoTW](3d-vision/localization/place-recognition/ral-2019-botw.md)
    * [\[IROS 2019\] CALC 2.0](3d-vision/localization/place-recognition/iros-2019-calc-2.0.md)
    * [\[RAL 2020\] CoHOG](3d-vision/localization/place-recognition/ral-2020-cohog.md)
    * [\[RAL 2020\] Delta Descriptors](3d-vision/localization/place-recognition/ral-2020-delta-descriptors.md)
    * [\[JFR 2021\] FILD++](3d-vision/localization/place-recognition/jfr-2021-fild++.md)
    * [\[CVPR 2021\] Patch-NetVLAD](3d-vision/localization/place-recognition/cvpr-2021-patch-netvlad.md)
    * [\[IJCAI 2021\] Visual Place Recognition](3d-vision/localization/place-recognition/ijcai-2021-visual-place-recognition.md)
    * [\[RAL 2021\] STA-VPR](3d-vision/localization/place-recognition/ral-2021-sta-vpr.md)
    * [\[RAL 2021\] SeqNet](3d-vision/localization/place-recognition/ral-2021-seqnet.md)
    * [\[CVPRW 2021\] SeqNetVLAD vs PointNetVLAD](3d-vision/localization/place-recognition/cvprw-2021-seqnetvlad-vs-pointnetvlad.md)
    * [\[BMVC 2020\] LiPo-LCD](3d-vision/localization/place-recognition/bmvc-2020-lipo-lcd.md)
    * [\[TIP 2021\] DASGIL](3d-vision/localization/place-recognition/tip-2021-dasgil.md)
    * [\[RAL 2021\] BVMatch](3d-vision/localization/place-recognition/ral-2021-bvmatch.md)
    * [\[MED 2022\] BK-tree indexing](3d-vision/localization/place-recognition/med-2022-bk-tree-indexing.md)
  * [scene coordinate regression](3d-vision/localization/scene-coordinate-regression/README.md)
    * [\[CVPR 2020\] HSCNet](3d-vision/localization/scene-coordinate-regression/cvpr-2020-hscnet.md)
    * [\[CVPR 2017\] DSAC](3d-vision/localization/scene-coordinate-regression/cvpr-2017-dsac.md)
    * [\[arxiv 2022\] NeuMap](3d-vision/localization/scene-coordinate-regression/arxiv-2022-neumap.md)
  * [matching with map](3d-vision/localization/matching-with-map/README.md)
    * [\[ICRA 2021\] HyperMap](3d-vision/localization/matching-with-map/icra-2021-hypermap.md)
    * [\[ICRAW 2020\] CMRNet++](3d-vision/localization/matching-with-map/icraw-2020-cmrnet++.md)
    * [\[ITSC 2021\] CMRNet](3d-vision/localization/matching-with-map/itsc-2021-cmrnet.md)
    * [\[CVPR 2021\] NRE](3d-vision/localization/matching-with-map/cvpr-2021-nre.md)
    * [\[CVPR 2021\] PixLoc](3d-vision/localization/matching-with-map/cvpr-2021-pixloc.md)
    * [\[ICCR 2020\] Pole Map](3d-vision/localization/matching-with-map/iccr-2020-pole-map.md)
    * [\[RAL 2018\] X-View](3d-vision/localization/matching-with-map/ral-2018-x-view.md)
    * [\[RAL 2021\] BVMatch](3d-vision/localization/matching-with-map/ral-2021-bvmatch.md)
    * [\[TITS 2022\] TM3Loc](3d-vision/localization/matching-with-map/tits-2022-tm3loc.md)
* [Positioning](3d-vision/positioning/README.md)
  * [\[IV 2019\] BEV-IPM](3d-vision/positioning/iv-2019-bev-ipm.md)

## DEEP LEARNING

* [model](deep-learning/model/README.md)
  * [\[neurocomputing 2020\] E2BoWs](deep-learning/model/neurocomputing-2020-e2bows.md)
  * [\[ICRA 2022\] OpenSceneVLAD](deep-learning/model/icra-2022-openscenevlad.md)
  * [\[CVPR 2020\] BoW-Net](deep-learning/model/cvpr-2020-bow-net.md)
  * [\[CVPR 2018\] Non-local Module](deep-learning/model/cvpr-2018-non-local-module.md)
  * [\[ICCV 2019\] MonoDepth2](deep-learning/model/iccv-2019-monodepth2.md)
  * [Transformer in Visual Tasks](deep-learning/model/transformer-in-visual-tasks/README.md)
    * [\[ICCV 2021\] VidTr](deep-learning/model/transformer-in-visual-tasks/iccv-2021-vidtr.md)
    * [\[arxiv 2021\] MLP-Mixer](deep-learning/model/transformer-in-visual-tasks/arxiv-2021-mlp-mixer.md)
    * [\[ECCV 2020\] DETR](deep-learning/model/transformer-in-visual-tasks/eccv-2020-detr.md)
    * [\[NIPS 2021\] Maskformer](deep-learning/model/transformer-in-visual-tasks/nips-2021-maskformer.md)
    * [\[arxiv 2021\] Mask2Former](deep-learning/model/transformer-in-visual-tasks/arxiv-2021-mask2former.md)
    * [\[ICASSP 2021\] CaTiLoc](deep-learning/model/transformer-in-visual-tasks/icassp-2021-catiloc.md)
    * [\[TPAMI 2022\] A Survey on Visual Transformer](deep-learning/model/transformer-in-visual-tasks/tpami-2022-a-survey-on-visual-transformer.md)
    * [\[CVPR 2020\] Token ViT](deep-learning/model/transformer-in-visual-tasks/cvpr-2020-token-vit.md)
    * [\[ICLR 2020\] ViT](deep-learning/model/transformer-in-visual-tasks/iclr-2020-vit.md)
* [dataset](deep-learning/dataset/README.md)
  * [\[CVPR 2019\] Cross-Season Correspondence Dataset](deep-learning/dataset/cvpr-2019-cross-season-correspondence-dataset.md)
* [loss function](deep-learning/loss-function/README.md)
  * [\[CVPR 2019\] AP-Loss](deep-learning/loss-function/cvpr-2019-ap-loss.md)
